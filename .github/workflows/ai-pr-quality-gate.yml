name: AI PR Quality Gate

# AI-powered PR review using GitHub Copilot CLI

# Invokes security, qa, and analyst agents to review PRs IN PARALLEL

# Blocks merge if CRITICAL_FAIL detected

on:
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
    # NO paths filter - use dorny/paths-filter internally to satisfy required checks

  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to review'
        required: true
        type: number
      enable_debouncing:
        description: 'Enable debouncing delay to reduce race conditions (adds 10s latency)'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  pull-requests: write

# Concurrency control: Attempts to cancel in-progress runs when new runs start

# NOTE: GitHub Actions does NOT guarantee run coalescing - race conditions can occur

# where multiple runs start before cancellation takes effect. This is best-effort

# See ADR-026 (../.agents/architecture/ADR-026-pr-automation-concurrency-and-safety.md)

# for architectural decision on workflow-level concurrency control

# Mitigation: Path filtering, timeouts, and PR-specific temp files reduce impact

# Note: 6 parallel agents use artifact-based result passing to avoid matrix output limitations

concurrency:
  group: ai-quality-${{ github.event.pull_request.number || inputs.pr_number }}
  cancel-in-progress: true

env:

# Compute PR number from either pull_request event or workflow_dispatch input

  PR_NUMBER: ${{ github.event.pull_request.number || inputs.pr_number }}

jobs:
  # Optional debouncing job - runs only when enable_debouncing=true
  debounce:
    name: Debounce Workflow
    if: (github.event_name == 'workflow_dispatch' && inputs.enable_debouncing == true) || (github.event_name == 'pull_request' && vars.ENABLE_DEBOUNCE == 'true')
    runs-on: ubuntu-24.04-arm
    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
      
      - name: Apply debouncing delay
        uses: ./.github/actions/workflow-debounce
        with:
          delay-seconds: '10'
          workflow-name: 'AI PR Quality Gate'
          concurrency-group: ${{ github.event.pull_request.number || inputs.pr_number }}

# Check if relevant files changed using paths-filter

  check-changes:
    name: Check Changes
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    needs: debounce
    if: |-
      always() &&
      (needs.debounce.result == 'success' || needs.debounce.result == 'skipped') &&
      github.actor != 'dependabot[bot]' && github.actor != 'github-actions[bot]'

    outputs:
      # For workflow_dispatch, always run review; otherwise use paths-filter result
      should-run: ${{ github.event_name == 'workflow_dispatch' && 'true' || steps.determine.outputs.should-run }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Check for relevant file changes
        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3
        id: filter
        # Skip paths-filter for workflow_dispatch as it may not have proper context
        if: github.event_name != 'workflow_dispatch'
        with:
          filters: |
            relevant:
              - 'src/**'
              - 'scripts/**'
              - 'build/**'
              - '.github/**'
              - '.agents/**'
              - '.claude/skills/**'

      - name: Determine if review should run
        id: determine
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "should-run=true" >> $GITHUB_OUTPUT
            echo "Decision: Run review (manual trigger)"
          else
            RELEVANT="${{ steps.filter.outputs.relevant }}"

            echo "Relevant files changed: $RELEVANT"

            # Run review if relevant files changed, skip otherwise
            if [ "$RELEVANT" = "true" ]; then
              echo "should-run=true" >> $GITHUB_OUTPUT
              echo "Decision: Run review (relevant files changed)"
            else
              echo "should-run=false" >> $GITHUB_OUTPUT
              echo "Decision: Skip review (no relevant files changed)"
            fi
          fi

# ==============================================================================
# Agent Review Jobs (6 Static Jobs)
# ==============================================================================
#
# Each agent (security, qa, analyst, architect, devops, roadmap) has a dedicated
# job with a static name. This ensures status check contexts are always emitted
# with proper names, even when reviews are skipped due to file filtering.
#
# Why not matrix? Job-level `if:` conditions prevent matrix expansion, leaving
# check context names as unresolved placeholders (e.g., "${{ matrix.agent }} Review").
# Static jobs with step-level conditionals solve this by:
# 1. Job names resolve at parse time (not runtime)
# 2. Jobs always run, emitting proper status checks
# 3. Composite action (.github/actions/agent-review) encapsulates common workflow
#
# Trade-off: Six job definitions (CVA) vs correctness (reliable status checks).

  security-review:
    name: security Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run security review
        uses: ./.github/actions/agent-review
        with:
          agent: security
          emoji: üîí
          prompt-file: .github/prompts/pr-quality-gate-security.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

  qa-review:
    name: qa Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run qa review
        uses: ./.github/actions/agent-review
        with:
          agent: qa
          emoji: üß™
          prompt-file: .github/prompts/pr-quality-gate-qa.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

  analyst-review:
    name: analyst Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run analyst review
        uses: ./.github/actions/agent-review
        with:
          agent: analyst
          emoji: üìä
          prompt-file: .github/prompts/pr-quality-gate-analyst.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

  architect-review:
    name: architect Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run architect review
        uses: ./.github/actions/agent-review
        with:
          agent: architect
          emoji: üìê
          prompt-file: .github/prompts/pr-quality-gate-architect.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

  devops-review:
    name: devops Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run devops review
        uses: ./.github/actions/agent-review
        with:
          agent: devops
          emoji: ‚öôÔ∏è
          prompt-file: .github/prompts/pr-quality-gate-devops.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

  roadmap-review:
    name: roadmap Review
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: always() && needs.check-changes.result == 'success'
    timeout-minutes: 10
    permissions:
      contents: read
      pull-requests: write

    steps:
      - name: Run roadmap review
        uses: ./.github/actions/agent-review
        with:
          agent: roadmap
          emoji: üó∫Ô∏è
          prompt-file: .github/prompts/pr-quality-gate-roadmap.md
          should-run: ${{ needs.check-changes.outputs.should-run }}
          pr-number: ${{ env.PR_NUMBER }}
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

# ==============================================================================
# Aggregate Results from All Agent Reviews
# ==============================================================================
#
# Depends on all six agent review jobs explicitly (not matrix).
# Downloads artifacts using pattern `review-*` to gather all agent verdicts.

  aggregate:
    name: Aggregate Results
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    needs: [check-changes, security-review, qa-review, analyst-review, architect-review, devops-review, roadmap-review]
    # Always run if check-changes ran and said to run, even if some agent jobs failed
    if: always() && needs.check-changes.outputs.should-run == 'true'

    outputs:
      final-verdict: ${{ steps.aggregate.outputs.final_verdict }}

    steps:
      - name: Check for failed agents
        id: failed-agents
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          # Check if any agent review jobs failed by examining the needs context
          # This step runs before downloading artifacts to surface failures early
          # Note: Specific failed agents are identified later by examining individual verdicts
          $securityResult = "${{ needs.security-review.result }}"
          $qaResult = "${{ needs.qa-review.result }}"
          $analystResult = "${{ needs.analyst-review.result }}"
          $architectResult = "${{ needs.architect-review.result }}"
          $devopsResult = "${{ needs.devops-review.result }}"
          $roadmapResult = "${{ needs.roadmap-review.result }}"

          $allResults = @($securityResult, $qaResult, $analystResult, $architectResult, $devopsResult, $roadmapResult)
          Write-Output "Individual review results:"
          Write-Output "  Security: $securityResult"
          Write-Output "  QA: $qaResult"
          Write-Output "  Analyst: $analystResult"
          Write-Output "  Architect: $architectResult"
          Write-Output "  DevOps: $devopsResult"
          Write-Output "  Roadmap: $roadmapResult"

          if ($allResults -contains "failure" -or $allResults -contains "cancelled") {
            "has_failures=true" >> $env:GITHUB_OUTPUT
            Write-Output "::warning::One or more agent review jobs failed - see individual job logs for details"
          } else {
            "has_failures=false" >> $env:GITHUB_OUTPUT
          }

      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Download all review artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093
        with:
          pattern: review-*
          path: ai-review-results
          merge-multiple: true

      - name: Load review results
        id: load-results
        run: |
          # Read verdicts from artifact files
          SECURITY_VERDICT=$(cat ai-review-results/security-verdict.txt 2>/dev/null || echo "UNKNOWN")
          QA_VERDICT=$(cat ai-review-results/qa-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ANALYST_VERDICT=$(cat ai-review-results/analyst-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ARCHITECT_VERDICT=$(cat ai-review-results/architect-verdict.txt 2>/dev/null || echo "UNKNOWN")
          DEVOPS_VERDICT=$(cat ai-review-results/devops-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ROADMAP_VERDICT=$(cat ai-review-results/roadmap-verdict.txt 2>/dev/null || echo "UNKNOWN")

          # Read infrastructure failure flags
          SECURITY_INFRA=$(cat ai-review-results/security-infrastructure-failure.txt 2>/dev/null || echo "false")
          QA_INFRA=$(cat ai-review-results/qa-infrastructure-failure.txt 2>/dev/null || echo "false")
          ANALYST_INFRA=$(cat ai-review-results/analyst-infrastructure-failure.txt 2>/dev/null || echo "false")
          ARCHITECT_INFRA=$(cat ai-review-results/architect-infrastructure-failure.txt 2>/dev/null || echo "false")
          DEVOPS_INFRA=$(cat ai-review-results/devops-infrastructure-failure.txt 2>/dev/null || echo "false")
          ROADMAP_INFRA=$(cat ai-review-results/roadmap-infrastructure-failure.txt 2>/dev/null || echo "false")

          echo "Loaded verdicts:"
          echo "  Security: $SECURITY_VERDICT (infra: $SECURITY_INFRA)"
          echo "  QA: $QA_VERDICT (infra: $QA_INFRA)"
          echo "  Analyst: $ANALYST_VERDICT (infra: $ANALYST_INFRA)"
          echo "  Architect: $ARCHITECT_VERDICT (infra: $ARCHITECT_INFRA)"
          echo "  DevOps: $DEVOPS_VERDICT (infra: $DEVOPS_INFRA)"
          echo "  Roadmap: $ROADMAP_VERDICT (infra: $ROADMAP_INFRA)"

          # Export verdicts for subsequent steps
          echo "security_verdict=$SECURITY_VERDICT" >> $GITHUB_OUTPUT
          echo "qa_verdict=$QA_VERDICT" >> $GITHUB_OUTPUT
          echo "analyst_verdict=$ANALYST_VERDICT" >> $GITHUB_OUTPUT
          echo "architect_verdict=$ARCHITECT_VERDICT" >> $GITHUB_OUTPUT
          echo "devops_verdict=$DEVOPS_VERDICT" >> $GITHUB_OUTPUT
          echo "roadmap_verdict=$ROADMAP_VERDICT" >> $GITHUB_OUTPUT

          # Export infrastructure failure flags
          echo "security_infra=$SECURITY_INFRA" >> $GITHUB_OUTPUT
          echo "qa_infra=$QA_INFRA" >> $GITHUB_OUTPUT
          echo "analyst_infra=$ANALYST_INFRA" >> $GITHUB_OUTPUT
          echo "architect_infra=$ARCHITECT_INFRA" >> $GITHUB_OUTPUT
          echo "devops_infra=$DEVOPS_INFRA" >> $GITHUB_OUTPUT
          echo "roadmap_infra=$ROADMAP_INFRA" >> $GITHUB_OUTPUT

      - name: Aggregate Verdicts
        id: aggregate
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          Import-Module "$env:GITHUB_WORKSPACE/.github/scripts/AIReviewCommon.psm1" -Force

          # Get verdicts from loaded results
          $securityVerdict = "${{ steps.load-results.outputs.security_verdict }}"
          $qaVerdict = "${{ steps.load-results.outputs.qa_verdict }}"
          $analystVerdict = "${{ steps.load-results.outputs.analyst_verdict }}"
          $architectVerdict = "${{ steps.load-results.outputs.architect_verdict }}"
          $devopsVerdict = "${{ steps.load-results.outputs.devops_verdict }}"
          $roadmapVerdict = "${{ steps.load-results.outputs.roadmap_verdict }}"

          # Get infrastructure failure flags
          $securityInfra = "${{ steps.load-results.outputs.security_infra }}" -eq "true"
          $qaInfra = "${{ steps.load-results.outputs.qa_infra }}" -eq "true"
          $analystInfra = "${{ steps.load-results.outputs.analyst_infra }}" -eq "true"
          $architectInfra = "${{ steps.load-results.outputs.architect_infra }}" -eq "true"
          $devopsInfra = "${{ steps.load-results.outputs.devops_infra }}" -eq "true"
          $roadmapInfra = "${{ steps.load-results.outputs.roadmap_infra }}" -eq "true"

          Write-Log "Security verdict: $securityVerdict (infra: $securityInfra)"
          Write-Log "QA verdict: $qaVerdict (infra: $qaInfra)"
          Write-Log "Analyst verdict: $analystVerdict (infra: $analystInfra)"
          Write-Log "Architect verdict: $architectVerdict (infra: $architectInfra)"
          Write-Log "DevOps verdict: $devopsVerdict (infra: $devopsInfra)"
          Write-Log "Roadmap verdict: $roadmapVerdict (infra: $roadmapInfra)"

          # Categorize failures: if verdict is failure AND infrastructure flag is true, it's INFRASTRUCTURE
          # Otherwise, it's CODE_QUALITY
          function Get-Category {
            param([string]$Verdict, [bool]$InfraFlag)
            if ($Verdict -in 'CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW') {
              if ($InfraFlag) { return 'INFRASTRUCTURE' } else { return 'CODE_QUALITY' }
            }
            return 'N/A'
          }

          $securityCategory = Get-Category -Verdict $securityVerdict -InfraFlag $securityInfra
          $qaCategory = Get-Category -Verdict $qaVerdict -InfraFlag $qaInfra
          $analystCategory = Get-Category -Verdict $analystVerdict -InfraFlag $analystInfra
          $architectCategory = Get-Category -Verdict $architectVerdict -InfraFlag $architectInfra
          $devopsCategory = Get-Category -Verdict $devopsVerdict -InfraFlag $devopsInfra
          $roadmapCategory = Get-Category -Verdict $roadmapVerdict -InfraFlag $roadmapInfra

          Write-Log "Security category: $securityCategory"
          Write-Log "QA category: $qaCategory"
          Write-Log "Analyst category: $analystCategory"
          Write-Log "Architect category: $architectCategory"
          Write-Log "DevOps category: $devopsCategory"
          Write-Log "Roadmap category: $roadmapCategory"

          # Determine if any CODE_QUALITY failures exist
          $codeQualityFailures = @($securityCategory, $qaCategory, $analystCategory, $architectCategory, $devopsCategory, $roadmapCategory) -contains 'CODE_QUALITY'

          # Merge all verdicts
          $final = Merge-Verdicts -Verdicts @($securityVerdict, $qaVerdict, $analystVerdict, $architectVerdict, $devopsVerdict, $roadmapVerdict)
          Write-Log "Final verdict: $final"

          # If final verdict is failure but no CODE_QUALITY failures, change to WARN
          if ($final -in 'CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW') {
            if (-not $codeQualityFailures) {
              Write-Log "All failures are INFRASTRUCTURE - downgrading to WARN (PR will not be blocked)"
              $final = 'WARN'
            }
          }

          "final_verdict=$final" >> $env:GITHUB_OUTPUT
          "security_verdict=$securityVerdict" >> $env:GITHUB_OUTPUT
          "qa_verdict=$qaVerdict" >> $env:GITHUB_OUTPUT
          "analyst_verdict=$analystVerdict" >> $env:GITHUB_OUTPUT
          "architect_verdict=$architectVerdict" >> $env:GITHUB_OUTPUT
          "devops_verdict=$devopsVerdict" >> $env:GITHUB_OUTPUT
          "roadmap_verdict=$roadmapVerdict" >> $env:GITHUB_OUTPUT

          # Output categories for PR comment
          "security_category=$securityCategory" >> $env:GITHUB_OUTPUT
          "qa_category=$qaCategory" >> $env:GITHUB_OUTPUT
          "analyst_category=$analystCategory" >> $env:GITHUB_OUTPUT
          "architect_category=$architectCategory" >> $env:GITHUB_OUTPUT
          "devops_category=$devopsCategory" >> $env:GITHUB_OUTPUT
          "roadmap_category=$roadmapCategory" >> $env:GITHUB_OUTPUT

      - name: Generate Report
        id: report
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
          REPOSITORY: ${{ github.repository }}
          EVENT_NAME: ${{ github.event_name }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          Import-Module "$env:GITHUB_WORKSPACE/.github/scripts/AIReviewCommon.psm1" -Force

          $reportDir = Initialize-AIReview
          $reportFile = Join-Path $reportDir "pr-quality-report.md"
          $finalVerdict = "${{ steps.aggregate.outputs.final_verdict }}"
          $alertType = Get-VerdictAlertType -Verdict $finalVerdict

          # Get verdicts
          $securityVerdict = "${{ steps.aggregate.outputs.security_verdict }}"
          $qaVerdict = "${{ steps.aggregate.outputs.qa_verdict }}"
          $analystVerdict = "${{ steps.aggregate.outputs.analyst_verdict }}"
          $architectVerdict = "${{ steps.aggregate.outputs.architect_verdict }}"
          $devopsVerdict = "${{ steps.aggregate.outputs.devops_verdict }}"
          $roadmapVerdict = "${{ steps.aggregate.outputs.roadmap_verdict }}"

          # Get categories
          $securityCategory = "${{ steps.aggregate.outputs.security_category }}"
          $qaCategory = "${{ steps.aggregate.outputs.qa_category }}"
          $analystCategory = "${{ steps.aggregate.outputs.analyst_category }}"
          $architectCategory = "${{ steps.aggregate.outputs.architect_category }}"
          $devopsCategory = "${{ steps.aggregate.outputs.devops_category }}"
          $roadmapCategory = "${{ steps.aggregate.outputs.roadmap_category }}"

          # Get emojis
          $securityEmoji = Get-VerdictEmoji -Verdict $securityVerdict
          $qaEmoji = Get-VerdictEmoji -Verdict $qaVerdict
          $analystEmoji = Get-VerdictEmoji -Verdict $analystVerdict
          $architectEmoji = Get-VerdictEmoji -Verdict $architectVerdict
          $devopsEmoji = Get-VerdictEmoji -Verdict $devopsVerdict
          $roadmapEmoji = Get-VerdictEmoji -Verdict $roadmapVerdict
          $finalEmoji = Get-VerdictEmoji -Verdict $finalVerdict

          # Build report content
          $report = @"
          <!-- AI-PR-QUALITY-GATE -->

          ## AI Quality Gate Review

          > [!$alertType]
          > $finalEmoji **Final Verdict: $finalVerdict**

          <details>
          <summary>Walkthrough</summary>

          This PR was reviewed by six AI agents **in parallel**, analyzing different aspects of the changes:

          - **Security Agent**: Scans for vulnerabilities, secrets exposure, and security anti-patterns
          - **QA Agent**: Evaluates test coverage, error handling, and code quality
          - **Analyst Agent**: Assesses code quality, impact analysis, and maintainability
          - **Architect Agent**: Reviews design patterns, system boundaries, and architectural concerns
          - **DevOps Agent**: Evaluates CI/CD, build pipelines, and infrastructure changes
          - **Roadmap Agent**: Assesses strategic alignment, feature scope, and user value

          </details>

          ### Review Summary

          | Agent | Verdict | Category | Status |
          |:------|:--------|:---------|:------:|
          | Security | $securityVerdict | $securityCategory | $securityEmoji |
          | QA | $qaVerdict | $qaCategory | $qaEmoji |
          | Analyst | $analystVerdict | $analystCategory | $analystEmoji |
          | Architect | $architectVerdict | $architectCategory | $architectEmoji |
          | DevOps | $devopsVerdict | $devopsCategory | $devopsEmoji |
          | Roadmap | $roadmapVerdict | $roadmapCategory | $roadmapEmoji |

          üí° **Quick Access**: Click on individual agent jobs (e.g., "üîí security Review", "üß™ qa Review") in the [workflow run]($env:SERVER_URL/$env:REPOSITORY/actions/runs/$env:RUN_ID) to see detailed findings and step summaries.

          "@

          # Add findings sections
          $findingsMap = @{
            'security' = 'Security Review Details'
            'qa' = 'QA Review Details'
            'analyst' = 'Analyst Review Details'
            'architect' = 'Architect Review Details'
            'devops' = 'DevOps Review Details'
            'roadmap' = 'Roadmap Review Details'
          }

          foreach ($agent in $findingsMap.Keys) {
            $findingsFile = "ai-review-results/$agent-findings.txt"
            if (Test-Path $findingsFile) {
              $findings = Get-Content $findingsFile -Raw
              if ($findings) {
                $title = $findingsMap[$agent]
                $report += "`n<details>`n<summary>$title</summary>`n`n$findings`n`n</details>`n"
              }
            } else {
              Write-Warning "No $agent findings file found"
            }
          }

          # Add footer
          $report += @"

          ---

          <details>
          <summary>Run Details</summary>

          | Property | Value |
          |:---------|:------|
          | **Run ID** | [$env:RUN_ID]($env:SERVER_URL/$env:REPOSITORY/actions/runs/$env:RUN_ID) |
          | **Triggered by** | ``$env:EVENT_NAME`` on ``$env:REF_NAME`` |
          | **Commit** | ``$env:SHA`` |

          </details>

          <sub>Powered by [AI Quality Gate](https://github.com/$env:REPOSITORY) workflow</sub>
          "@

          $report | Set-Content $reportFile -Encoding UTF8
          "report_file=$reportFile" >> $env:GITHUB_OUTPUT

      - name: Check for infrastructure failures and add label
        continue-on-error: true
        shell: pwsh
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
        run: |
          # Check if any agent had infrastructure failure (Issue #328)
          $infrastructureFailureDetected = $false
          $retryAttempts = @()

          $agents = @('security', 'qa', 'analyst', 'architect', 'devops', 'roadmap')

          foreach ($agent in $agents) {
            $infraFile = "ai-review-results/$agent-infrastructure-failure.txt"
            $retryFile = "ai-review-results/$agent-retry-count.txt"

            if (Test-Path $infraFile) {
              $infraFlag = (Get-Content $infraFile -Raw).Trim()
              if ($infraFlag -eq "true") {
                $infrastructureFailureDetected = $true
                $retryCount = 0
                if (Test-Path $retryFile) {
                  $retryCount = [int](Get-Content $retryFile -Raw).Trim()
                }
                $retryAttempts += "${agent}: $retryCount retries"
                Write-Output "::notice::Infrastructure failure detected for $agent agent (retries: $retryCount)"
              }
            }
          }

          if ($infrastructureFailureDetected) {
            Write-Output "::warning::Infrastructure failures detected - adding infrastructure-failure label"
            Write-Output "Retry attempts: $($retryAttempts -join ', ')"

            # Add infrastructure-failure label to PR
            gh pr edit $env:PR_NUMBER --repo $env:GITHUB_REPOSITORY --add-label "infrastructure-failure"
          } else {
            Write-Output "No infrastructure failures detected"
          }

      - name: Post PR Comment
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
          REPORT_FILE: ${{ steps.report.outputs.report_file }}
        run: |
          # Use GitHub skill script for idempotent comment posting
          # PRs are issues in GitHub API, so we use Post-IssueComment with marker
          # UpdateIfExists updates the existing marked comment if present, ensuring the latest report is reflected
          & .claude/skills/github/scripts/issue/Post-IssueComment.ps1 `
            -Issue $env:PR_NUMBER `
            -BodyFile $env:REPORT_FILE `
            -Marker "AI-PR-QUALITY-GATE" `
            -UpdateIfExists

      - name: Set Job Summary
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          REPORT_FILE: ${{ steps.report.outputs.report_file }}
        run: |
          Get-Content $env:REPORT_FILE | Add-Content $env:GITHUB_STEP_SUMMARY

      - name: Check for Critical Failures
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          $finalVerdict = "${{ steps.aggregate.outputs.final_verdict }}"

          # Use ordered array for deterministic output (dictionary Keys property is unordered)
          $agentVerdicts = @(
            @{ Name = 'üîí Security'; Verdict = "${{ steps.aggregate.outputs.security_verdict }}" }
            @{ Name = 'üß™ QA'; Verdict = "${{ steps.aggregate.outputs.qa_verdict }}" }
            @{ Name = 'üìä Analyst'; Verdict = "${{ steps.aggregate.outputs.analyst_verdict }}" }
            @{ Name = 'üìê Architect'; Verdict = "${{ steps.aggregate.outputs.architect_verdict }}" }
            @{ Name = '‚öôÔ∏è DevOps'; Verdict = "${{ steps.aggregate.outputs.devops_verdict }}" }
            @{ Name = 'üó∫Ô∏è Roadmap'; Verdict = "${{ steps.aggregate.outputs.roadmap_verdict }}" }
          )

          # Identify agents with blocking verdicts
          # NEEDS_REVIEW added in Issue #470 fix - indicates AI couldn't produce explicit verdict
          $blockingVerdicts = @('CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW')
          $failedAgents = @()

          foreach ($entry in $agentVerdicts) {
            if ([string]::IsNullOrWhiteSpace($entry.Verdict)) {
              Write-Output "::warning::$($entry.Name): No verdict received from aggregate step"
              continue
            }
            if ($entry.Verdict -in $blockingVerdicts) {
              $failedAgents += "$($entry.Name): $($entry.Verdict)"
              Write-Output "::error::$($entry.Name): $($entry.Verdict)"
            }
          }

          if ($finalVerdict -in $blockingVerdicts) {
            Write-Output ""
            Write-Output "‚ùå AI Quality Gate FAILED"
            Write-Output ""
            Write-Output "Agents with blocking verdicts:"
            foreach ($failed in $failedAgents) {
              Write-Output "  - $failed"
            }
            Write-Output ""
            Write-Output "Click on individual agent jobs above to see detailed findings."
            exit 1
          }

          Write-Output "‚úÖ AI Quality Gate passed with verdict: $finalVerdict"

# Skip jobs that provide passing status when no relevant files changed
