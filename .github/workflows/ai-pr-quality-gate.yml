name: AI PR Quality Gate

# AI-powered PR review using GitHub Copilot CLI

# Invokes security, qa, and analyst agents to review PRs IN PARALLEL

# Blocks merge if CRITICAL_FAIL detected

on:
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]
    # NO paths filter - use dorny/paths-filter internally to satisfy required checks

  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number to review'
        required: true
        type: number

permissions:
  contents: read
  pull-requests: write

concurrency:
  group: ai-quality-${{ github.event.pull_request.number || inputs.pr_number }}
  cancel-in-progress: true

env:

# Compute PR number from either pull_request event or workflow_dispatch input

  PR_NUMBER: ${{ github.event.pull_request.number || inputs.pr_number }}

jobs:

# Check if relevant files changed using paths-filter

  check-changes:
    name: Check Changes
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    if: github.actor != 'dependabot[bot]' && github.actor != 'github-actions[bot]'

    outputs:
      # For workflow_dispatch, always run review; otherwise use paths-filter result
      should-run: ${{ github.event_name == 'workflow_dispatch' && 'true' || steps.determine.outputs.should-run }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Check for relevant file changes
        uses: dorny/paths-filter@de90cc6fb38fc0963ad72b210f1f284cd68cea36 # v3
        id: filter
        # Skip paths-filter for workflow_dispatch as it may not have proper context
        if: github.event_name != 'workflow_dispatch'
        with:
          filters: |
            relevant:
              - 'src/**'
              - 'scripts/**'
              - 'build/**'
              - '.github/**'
              - '.agents/**'
              - '.claude/skills/**'

      - name: Determine if review should run
        id: determine
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "should-run=true" >> $GITHUB_OUTPUT
            echo "Decision: Run review (manual trigger)"
          else
            RELEVANT="${{ steps.filter.outputs.relevant }}"

            echo "Relevant files changed: $RELEVANT"

            # Run review if relevant files changed, skip otherwise
            if [ "$RELEVANT" = "true" ]; then
              echo "should-run=true" >> $GITHUB_OUTPUT
              echo "Decision: Run review (relevant files changed)"
            else
              echo "should-run=false" >> $GITHUB_OUTPUT
              echo "Decision: Skip review (no relevant files changed)"
            fi
          fi

# Run all three reviews in parallel using matrix strategy

  review:
    name: ${{ matrix.agent }} Review
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    needs: check-changes
    if: needs.check-changes.outputs.should-run == 'true'
    timeout-minutes: 10

    strategy:
      fail-fast: false  # Don't cancel other reviews if one fails
      matrix:
        include:
          - agent: security
            prompt-file: .github/prompts/pr-quality-gate-security.md
            emoji: "üîí"
          - agent: qa
            prompt-file: .github/prompts/pr-quality-gate-qa.md
            emoji: "üß™"
          - agent: analyst
            prompt-file: .github/prompts/pr-quality-gate-analyst.md
            emoji: "üìä"
          - agent: architect
            prompt-file: .github/prompts/pr-quality-gate-architect.md
            emoji: "üìê"
          - agent: devops
            prompt-file: .github/prompts/pr-quality-gate-devops.md
            emoji: "‚öôÔ∏è"
          - agent: roadmap
            prompt-file: .github/prompts/pr-quality-gate-roadmap.md
            emoji: "üó∫Ô∏è"

    # NOTE: Matrix job outputs only expose ONE matrix leg's outputs to downstream jobs.
    # We use artifacts instead to reliably pass findings between jobs.
    # Verdicts use job outputs (small strings, safe for interpolation).

    steps:
      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5
        with:
          fetch-depth: 0

      - name: ${{ matrix.emoji }} ${{ matrix.agent }} Review
        id: review
        uses: ./.github/actions/ai-review
        with:
          agent: ${{ matrix.agent }}
          context-type: pr-diff
          pr-number: ${{ env.PR_NUMBER }}
          prompt-file: ${{ matrix.prompt-file }}
          timeout-minutes: 5
          bot-pat: ${{ secrets.BOT_PAT }}
          copilot-token: ${{ secrets.COPILOT_GITHUB_TOKEN }}

      - name: Save review results
        id: save-results
        env:
          AGENT: ${{ matrix.agent }}
          VERDICT: ${{ steps.review.outputs.verdict }}
          FINDINGS: ${{ steps.review.outputs.findings }}
          INFRASTRUCTURE_FAILURE: ${{ steps.review.outputs.infrastructure-failure }}
          RETRY_COUNT: ${{ steps.review.outputs.retry-count }}
        run: |
          # Create output directory for this agent's results
          mkdir -p ai-review-results

          # Write verdict (safe for job outputs - small string)
          echo "$VERDICT" > "ai-review-results/${AGENT}-verdict.txt"

          # Write findings to file (avoids shell interpolation issues with special chars)
          echo "$FINDINGS" > "ai-review-results/${AGENT}-findings.txt"

          # Write infrastructure failure flag (Issue #328)
          echo "$INFRASTRUCTURE_FAILURE" > "ai-review-results/${AGENT}-infrastructure-failure.txt"

          # Write retry count (Issue #328)
          echo "$RETRY_COUNT" > "ai-review-results/${AGENT}-retry-count.txt"

          echo "Saved ${AGENT} results:"
          echo "  Verdict: $VERDICT"
          echo "  Findings: $(wc -c < ai-review-results/${AGENT}-findings.txt) bytes"
          echo "  Infrastructure failure: $INFRASTRUCTURE_FAILURE"
          echo "  Retry count: $RETRY_COUNT"

      - name: Upload review results
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02
        with:
          name: review-${{ matrix.agent }}
          path: ai-review-results/
          retention-days: 1

      - name: Generate step summary
        if: always()
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          AGENT: ${{ matrix.agent }}
          EMOJI: ${{ matrix.emoji }}
          VERDICT: ${{ steps.review.outputs.verdict }}
          FINDINGS: ${{ steps.review.outputs.findings }}
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
          REPOSITORY: ${{ github.repository }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
        run: |
          Import-Module "$env:GITHUB_WORKSPACE/.github/scripts/AIReviewCommon.psm1" -Force

          $verdict = $env:VERDICT
          $agent = $env:AGENT
          $emoji = $env:EMOJI
          $findings = $env:FINDINGS
          $prNumber = $env:PR_NUMBER

          # Get alert type for verdict
          $alertType = Get-VerdictAlertType -Verdict $verdict
          $verdictEmoji = Get-VerdictEmoji -Verdict $verdict

          # Capitalize agent name (handle empty string case)
          $agentDisplay = if ($agent) { (Get-Culture).TextInfo.ToTitleCase($agent.ToLower()) } else { "Unknown" }

          # Build step summary
          $summary = @"
          ## $emoji $agentDisplay Review

          > [!$alertType]
          > $verdictEmoji **Verdict: $verdict**

          <details>
          <summary>Review Findings</summary>

          $findings

          </details>

          ---

          <sub>üí° See the [workflow run]($env:SERVER_URL/$env:REPOSITORY/actions/runs/$env:RUN_ID) for full context across all agents, or check the PR for the consolidated quality gate comment.</sub>
          "@

          # Write to step summary
          $summary | Add-Content $env:GITHUB_STEP_SUMMARY -Encoding UTF8

      - name: Check verdict and fail if needed
        if: always()
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          AGENT: ${{ matrix.agent }}
          EMOJI: ${{ matrix.emoji }}
          VERDICT: ${{ steps.review.outputs.verdict }}
          FINDINGS: ${{ steps.review.outputs.findings }}
        run: |
          $agent = $env:AGENT
          $emoji = $env:EMOJI
          $verdict = $env:VERDICT
          $findings = $env:FINDINGS

          # Check if verdict indicates a blocking failure
          # NEEDS_REVIEW added in Issue #470 fix - indicates AI couldn't produce explicit verdict
          $blockingVerdicts = @('CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW')

          if ($verdict -in $blockingVerdicts) {
            # GitHub Actions annotations have a practical limit of ~200 chars for readability
            # We truncate to 180 chars (177 + "...") to leave room for the prefix "[agent] VERDICT: "
            $maxAnnotationLength = 180
            if ([string]::IsNullOrWhiteSpace($findings)) {
              $summary = "No details available."
            } else {
              $summary = ($findings -replace "`n", " ")
              if ($summary.Length -gt $maxAnnotationLength) {
                $summary = $summary.Substring(0, $maxAnnotationLength - 3) + "..."
              }
            }

            Write-Output "::error::[$agent] ${verdict}: $summary"
            Write-Output ""
            Write-Output "‚ùå $emoji $agent review failed with verdict: $verdict"
            Write-Output ""
            Write-Output "See the step summary above for full findings."
            exit 1
          }

          Write-Output "‚úÖ $emoji $agent review passed with verdict: $verdict"

# Aggregate results from all parallel reviews

  aggregate:
    name: Aggregate Results
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    needs: [check-changes, review]
    # Always run if check-changes ran and said to run, even if some matrix jobs failed
    if: always() && needs.check-changes.outputs.should-run == 'true'

    outputs:
      final-verdict: ${{ steps.aggregate.outputs.final_verdict }}

    steps:
      - name: Check for failed agents
        id: failed-agents
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          # Check if any matrix jobs failed by examining the needs context
          # This step runs before downloading artifacts to surface failures early
          # Note: Specific failed agents are identified later by examining individual verdicts
          $reviewResult = "${{ needs.review.result }}"
          Write-Output "Review matrix result: $reviewResult"

          if ($reviewResult -eq "failure" -or $reviewResult -eq "cancelled") {
            "has_failures=true" >> $env:GITHUB_OUTPUT
            Write-Output "::warning::One or more agent review jobs failed - see individual job logs for details"
          } else {
            "has_failures=false" >> $env:GITHUB_OUTPUT
          }

      - name: Checkout repository
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5

      - name: Download all review artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093
        with:
          pattern: review-*
          path: ai-review-results
          merge-multiple: true

      - name: Load review results
        id: load-results
        run: |
          # Read verdicts from artifact files
          SECURITY_VERDICT=$(cat ai-review-results/security-verdict.txt 2>/dev/null || echo "UNKNOWN")
          QA_VERDICT=$(cat ai-review-results/qa-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ANALYST_VERDICT=$(cat ai-review-results/analyst-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ARCHITECT_VERDICT=$(cat ai-review-results/architect-verdict.txt 2>/dev/null || echo "UNKNOWN")
          DEVOPS_VERDICT=$(cat ai-review-results/devops-verdict.txt 2>/dev/null || echo "UNKNOWN")
          ROADMAP_VERDICT=$(cat ai-review-results/roadmap-verdict.txt 2>/dev/null || echo "UNKNOWN")

          # Read infrastructure failure flags
          SECURITY_INFRA=$(cat ai-review-results/security-infrastructure-failure.txt 2>/dev/null || echo "false")
          QA_INFRA=$(cat ai-review-results/qa-infrastructure-failure.txt 2>/dev/null || echo "false")
          ANALYST_INFRA=$(cat ai-review-results/analyst-infrastructure-failure.txt 2>/dev/null || echo "false")
          ARCHITECT_INFRA=$(cat ai-review-results/architect-infrastructure-failure.txt 2>/dev/null || echo "false")
          DEVOPS_INFRA=$(cat ai-review-results/devops-infrastructure-failure.txt 2>/dev/null || echo "false")
          ROADMAP_INFRA=$(cat ai-review-results/roadmap-infrastructure-failure.txt 2>/dev/null || echo "false")

          echo "Loaded verdicts:"
          echo "  Security: $SECURITY_VERDICT (infra: $SECURITY_INFRA)"
          echo "  QA: $QA_VERDICT (infra: $QA_INFRA)"
          echo "  Analyst: $ANALYST_VERDICT (infra: $ANALYST_INFRA)"
          echo "  Architect: $ARCHITECT_VERDICT (infra: $ARCHITECT_INFRA)"
          echo "  DevOps: $DEVOPS_VERDICT (infra: $DEVOPS_INFRA)"
          echo "  Roadmap: $ROADMAP_VERDICT (infra: $ROADMAP_INFRA)"

          # Export verdicts for subsequent steps
          echo "security_verdict=$SECURITY_VERDICT" >> $GITHUB_OUTPUT
          echo "qa_verdict=$QA_VERDICT" >> $GITHUB_OUTPUT
          echo "analyst_verdict=$ANALYST_VERDICT" >> $GITHUB_OUTPUT
          echo "architect_verdict=$ARCHITECT_VERDICT" >> $GITHUB_OUTPUT
          echo "devops_verdict=$DEVOPS_VERDICT" >> $GITHUB_OUTPUT
          echo "roadmap_verdict=$ROADMAP_VERDICT" >> $GITHUB_OUTPUT

          # Export infrastructure failure flags
          echo "security_infra=$SECURITY_INFRA" >> $GITHUB_OUTPUT
          echo "qa_infra=$QA_INFRA" >> $GITHUB_OUTPUT
          echo "analyst_infra=$ANALYST_INFRA" >> $GITHUB_OUTPUT
          echo "architect_infra=$ARCHITECT_INFRA" >> $GITHUB_OUTPUT
          echo "devops_infra=$DEVOPS_INFRA" >> $GITHUB_OUTPUT
          echo "roadmap_infra=$ROADMAP_INFRA" >> $GITHUB_OUTPUT

      - name: Aggregate Verdicts
        id: aggregate
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          Import-Module "$env:GITHUB_WORKSPACE/.github/scripts/AIReviewCommon.psm1" -Force

          # Get verdicts from loaded results
          $securityVerdict = "${{ steps.load-results.outputs.security_verdict }}"
          $qaVerdict = "${{ steps.load-results.outputs.qa_verdict }}"
          $analystVerdict = "${{ steps.load-results.outputs.analyst_verdict }}"
          $architectVerdict = "${{ steps.load-results.outputs.architect_verdict }}"
          $devopsVerdict = "${{ steps.load-results.outputs.devops_verdict }}"
          $roadmapVerdict = "${{ steps.load-results.outputs.roadmap_verdict }}"

          # Get infrastructure failure flags
          $securityInfra = "${{ steps.load-results.outputs.security_infra }}" -eq "true"
          $qaInfra = "${{ steps.load-results.outputs.qa_infra }}" -eq "true"
          $analystInfra = "${{ steps.load-results.outputs.analyst_infra }}" -eq "true"
          $architectInfra = "${{ steps.load-results.outputs.architect_infra }}" -eq "true"
          $devopsInfra = "${{ steps.load-results.outputs.devops_infra }}" -eq "true"
          $roadmapInfra = "${{ steps.load-results.outputs.roadmap_infra }}" -eq "true"

          Write-Log "Security verdict: $securityVerdict (infra: $securityInfra)"
          Write-Log "QA verdict: $qaVerdict (infra: $qaInfra)"
          Write-Log "Analyst verdict: $analystVerdict (infra: $analystInfra)"
          Write-Log "Architect verdict: $architectVerdict (infra: $architectInfra)"
          Write-Log "DevOps verdict: $devopsVerdict (infra: $devopsInfra)"
          Write-Log "Roadmap verdict: $roadmapVerdict (infra: $roadmapInfra)"

          # Categorize failures: if verdict is failure AND infrastructure flag is true, it's INFRASTRUCTURE
          # Otherwise, it's CODE_QUALITY
          function Get-Category {
            param([string]$Verdict, [bool]$InfraFlag)
            if ($Verdict -in 'CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW') {
              if ($InfraFlag) { return 'INFRASTRUCTURE' } else { return 'CODE_QUALITY' }
            }
            return 'N/A'
          }

          $securityCategory = Get-Category -Verdict $securityVerdict -InfraFlag $securityInfra
          $qaCategory = Get-Category -Verdict $qaVerdict -InfraFlag $qaInfra
          $analystCategory = Get-Category -Verdict $analystVerdict -InfraFlag $analystInfra
          $architectCategory = Get-Category -Verdict $architectVerdict -InfraFlag $architectInfra
          $devopsCategory = Get-Category -Verdict $devopsVerdict -InfraFlag $devopsInfra
          $roadmapCategory = Get-Category -Verdict $roadmapVerdict -InfraFlag $roadmapInfra

          Write-Log "Security category: $securityCategory"
          Write-Log "QA category: $qaCategory"
          Write-Log "Analyst category: $analystCategory"
          Write-Log "Architect category: $architectCategory"
          Write-Log "DevOps category: $devopsCategory"
          Write-Log "Roadmap category: $roadmapCategory"

          # Determine if any CODE_QUALITY failures exist
          $codeQualityFailures = @($securityCategory, $qaCategory, $analystCategory, $architectCategory, $devopsCategory, $roadmapCategory) -contains 'CODE_QUALITY'

          # Merge all verdicts
          $final = Merge-Verdicts -Verdicts @($securityVerdict, $qaVerdict, $analystVerdict, $architectVerdict, $devopsVerdict, $roadmapVerdict)
          Write-Log "Final verdict: $final"

          # If final verdict is failure but no CODE_QUALITY failures, change to WARN
          if ($final -in 'CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW') {
            if (-not $codeQualityFailures) {
              Write-Log "All failures are INFRASTRUCTURE - downgrading to WARN (PR will not be blocked)"
              $final = 'WARN'
            }
          }

          "final_verdict=$final" >> $env:GITHUB_OUTPUT
          "security_verdict=$securityVerdict" >> $env:GITHUB_OUTPUT
          "qa_verdict=$qaVerdict" >> $env:GITHUB_OUTPUT
          "analyst_verdict=$analystVerdict" >> $env:GITHUB_OUTPUT
          "architect_verdict=$architectVerdict" >> $env:GITHUB_OUTPUT
          "devops_verdict=$devopsVerdict" >> $env:GITHUB_OUTPUT
          "roadmap_verdict=$roadmapVerdict" >> $env:GITHUB_OUTPUT

          # Output categories for PR comment
          "security_category=$securityCategory" >> $env:GITHUB_OUTPUT
          "qa_category=$qaCategory" >> $env:GITHUB_OUTPUT
          "analyst_category=$analystCategory" >> $env:GITHUB_OUTPUT
          "architect_category=$architectCategory" >> $env:GITHUB_OUTPUT
          "devops_category=$devopsCategory" >> $env:GITHUB_OUTPUT
          "roadmap_category=$roadmapCategory" >> $env:GITHUB_OUTPUT

      - name: Generate Report
        id: report
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          RUN_ID: ${{ github.run_id }}
          SERVER_URL: ${{ github.server_url }}
          REPOSITORY: ${{ github.repository }}
          EVENT_NAME: ${{ github.event_name }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          Import-Module "$env:GITHUB_WORKSPACE/.github/scripts/AIReviewCommon.psm1" -Force

          $reportDir = Initialize-AIReview
          $reportFile = Join-Path $reportDir "pr-quality-report.md"
          $finalVerdict = "${{ steps.aggregate.outputs.final_verdict }}"
          $alertType = Get-VerdictAlertType -Verdict $finalVerdict

          # Get verdicts
          $securityVerdict = "${{ steps.aggregate.outputs.security_verdict }}"
          $qaVerdict = "${{ steps.aggregate.outputs.qa_verdict }}"
          $analystVerdict = "${{ steps.aggregate.outputs.analyst_verdict }}"
          $architectVerdict = "${{ steps.aggregate.outputs.architect_verdict }}"
          $devopsVerdict = "${{ steps.aggregate.outputs.devops_verdict }}"
          $roadmapVerdict = "${{ steps.aggregate.outputs.roadmap_verdict }}"

          # Get categories
          $securityCategory = "${{ steps.aggregate.outputs.security_category }}"
          $qaCategory = "${{ steps.aggregate.outputs.qa_category }}"
          $analystCategory = "${{ steps.aggregate.outputs.analyst_category }}"
          $architectCategory = "${{ steps.aggregate.outputs.architect_category }}"
          $devopsCategory = "${{ steps.aggregate.outputs.devops_category }}"
          $roadmapCategory = "${{ steps.aggregate.outputs.roadmap_category }}"

          # Get emojis
          $securityEmoji = Get-VerdictEmoji -Verdict $securityVerdict
          $qaEmoji = Get-VerdictEmoji -Verdict $qaVerdict
          $analystEmoji = Get-VerdictEmoji -Verdict $analystVerdict
          $architectEmoji = Get-VerdictEmoji -Verdict $architectVerdict
          $devopsEmoji = Get-VerdictEmoji -Verdict $devopsVerdict
          $roadmapEmoji = Get-VerdictEmoji -Verdict $roadmapVerdict
          $finalEmoji = Get-VerdictEmoji -Verdict $finalVerdict

          # Build report content
          $report = @"
          <!-- AI-PR-QUALITY-GATE -->

          ## AI Quality Gate Review

          > [!$alertType]
          > $finalEmoji **Final Verdict: $finalVerdict**

          <details>
          <summary>Walkthrough</summary>

          This PR was reviewed by six AI agents **in parallel**, analyzing different aspects of the changes:

          - **Security Agent**: Scans for vulnerabilities, secrets exposure, and security anti-patterns
          - **QA Agent**: Evaluates test coverage, error handling, and code quality
          - **Analyst Agent**: Assesses code quality, impact analysis, and maintainability
          - **Architect Agent**: Reviews design patterns, system boundaries, and architectural concerns
          - **DevOps Agent**: Evaluates CI/CD, build pipelines, and infrastructure changes
          - **Roadmap Agent**: Assesses strategic alignment, feature scope, and user value

          </details>

          ### Review Summary

          | Agent | Verdict | Category | Status |
          |:------|:--------|:---------|:------:|
          | Security | $securityVerdict | $securityCategory | $securityEmoji |
          | QA | $qaVerdict | $qaCategory | $qaEmoji |
          | Analyst | $analystVerdict | $analystCategory | $analystEmoji |
          | Architect | $architectVerdict | $architectCategory | $architectEmoji |
          | DevOps | $devopsVerdict | $devopsCategory | $devopsEmoji |
          | Roadmap | $roadmapVerdict | $roadmapCategory | $roadmapEmoji |

          üí° **Quick Access**: Click on individual agent jobs (e.g., "üîí security Review", "üß™ qa Review") in the [workflow run]($env:SERVER_URL/$env:REPOSITORY/actions/runs/$env:RUN_ID) to see detailed findings and step summaries.

          "@

          # Add findings sections
          $findingsMap = @{
            'security' = 'Security Review Details'
            'qa' = 'QA Review Details'
            'analyst' = 'Analyst Review Details'
            'architect' = 'Architect Review Details'
            'devops' = 'DevOps Review Details'
            'roadmap' = 'Roadmap Review Details'
          }

          foreach ($agent in $findingsMap.Keys) {
            $findingsFile = "ai-review-results/$agent-findings.txt"
            if (Test-Path $findingsFile) {
              $findings = Get-Content $findingsFile -Raw
              if ($findings) {
                $title = $findingsMap[$agent]
                $report += "`n<details>`n<summary>$title</summary>`n`n$findings`n`n</details>`n"
              }
            } else {
              Write-Warning "No $agent findings file found"
            }
          }

          # Add footer
          $report += @"

          ---

          <details>
          <summary>Run Details</summary>

          | Property | Value |
          |:---------|:------|
          | **Run ID** | [$env:RUN_ID]($env:SERVER_URL/$env:REPOSITORY/actions/runs/$env:RUN_ID) |
          | **Triggered by** | ``$env:EVENT_NAME`` on ``$env:REF_NAME`` |
          | **Commit** | ``$env:SHA`` |

          </details>

          <sub>Powered by [AI Quality Gate](https://github.com/$env:REPOSITORY) workflow</sub>
          "@

          $report | Set-Content $reportFile -Encoding UTF8
          "report_file=$reportFile" >> $env:GITHUB_OUTPUT

      - name: Check for infrastructure failures and add label
        continue-on-error: true
        shell: pwsh
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
        run: |
          # Check if any agent had infrastructure failure (Issue #328)
          $infrastructureFailureDetected = $false
          $retryAttempts = @()

          $agents = @('security', 'qa', 'analyst', 'architect', 'devops', 'roadmap')

          foreach ($agent in $agents) {
            $infraFile = "ai-review-results/$agent-infrastructure-failure.txt"
            $retryFile = "ai-review-results/$agent-retry-count.txt"

            if (Test-Path $infraFile) {
              $infraFlag = (Get-Content $infraFile -Raw).Trim()
              if ($infraFlag -eq "true") {
                $infrastructureFailureDetected = $true
                $retryCount = 0
                if (Test-Path $retryFile) {
                  $retryCount = [int](Get-Content $retryFile -Raw).Trim()
                }
                $retryAttempts += "${agent}: $retryCount retries"
                Write-Output "::notice::Infrastructure failure detected for $agent agent (retries: $retryCount)"
              }
            }
          }

          if ($infrastructureFailureDetected) {
            Write-Output "::warning::Infrastructure failures detected - adding infrastructure-failure label"
            Write-Output "Retry attempts: $($retryAttempts -join ', ')"

            # Add infrastructure-failure label to PR
            gh pr edit $env:PR_NUMBER --add-label "infrastructure-failure"
          } else {
            Write-Output "No infrastructure failures detected"
          }

      - name: Post PR Comment
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          GH_TOKEN: ${{ github.token }}
          PR_NUMBER: ${{ env.PR_NUMBER }}
          REPORT_FILE: ${{ steps.report.outputs.report_file }}
        run: |
          # Use GitHub skill script for idempotent comment posting
          # PRs are issues in GitHub API, so we use Post-IssueComment with marker
          # UpdateIfExists updates the existing marked comment if present, ensuring the latest report is reflected
          & .claude/skills/github/scripts/issue/Post-IssueComment.ps1 `
            -Issue $env:PR_NUMBER `
            -BodyFile $env:REPORT_FILE `
            -Marker "AI-PR-QUALITY-GATE" `
            -UpdateIfExists

      - name: Set Job Summary
        shell: pwsh -NoProfile -Command "& '{0}'"
        env:
          REPORT_FILE: ${{ steps.report.outputs.report_file }}
        run: |
          Get-Content $env:REPORT_FILE | Add-Content $env:GITHUB_STEP_SUMMARY

      - name: Check for Critical Failures
        shell: pwsh -NoProfile -Command "& '{0}'"
        run: |
          $finalVerdict = "${{ steps.aggregate.outputs.final_verdict }}"

          # Use ordered array for deterministic output (dictionary Keys property is unordered)
          $agentVerdicts = @(
            @{ Name = 'üîí Security'; Verdict = "${{ steps.aggregate.outputs.security_verdict }}" }
            @{ Name = 'üß™ QA'; Verdict = "${{ steps.aggregate.outputs.qa_verdict }}" }
            @{ Name = 'üìä Analyst'; Verdict = "${{ steps.aggregate.outputs.analyst_verdict }}" }
            @{ Name = 'üìê Architect'; Verdict = "${{ steps.aggregate.outputs.architect_verdict }}" }
            @{ Name = '‚öôÔ∏è DevOps'; Verdict = "${{ steps.aggregate.outputs.devops_verdict }}" }
            @{ Name = 'üó∫Ô∏è Roadmap'; Verdict = "${{ steps.aggregate.outputs.roadmap_verdict }}" }
          )

          # Identify agents with blocking verdicts
          # NEEDS_REVIEW added in Issue #470 fix - indicates AI couldn't produce explicit verdict
          $blockingVerdicts = @('CRITICAL_FAIL', 'REJECTED', 'FAIL', 'NEEDS_REVIEW')
          $failedAgents = @()

          foreach ($entry in $agentVerdicts) {
            if ([string]::IsNullOrWhiteSpace($entry.Verdict)) {
              Write-Output "::warning::$($entry.Name): No verdict received from aggregate step"
              continue
            }
            if ($entry.Verdict -in $blockingVerdicts) {
              $failedAgents += "$($entry.Name): $($entry.Verdict)"
              Write-Output "::error::$($entry.Name): $($entry.Verdict)"
            }
          }

          if ($finalVerdict -in $blockingVerdicts) {
            Write-Output ""
            Write-Output "‚ùå AI Quality Gate FAILED"
            Write-Output ""
            Write-Output "Agents with blocking verdicts:"
            foreach ($failed in $failedAgents) {
              Write-Output "  - $failed"
            }
            Write-Output ""
            Write-Output "Click on individual agent jobs above to see detailed findings."
            exit 1
          }

          Write-Output "‚úÖ AI Quality Gate passed with verdict: $finalVerdict"

# Skip jobs that provide passing status when no relevant files changed
# NOTE: We need TWO skip jobs with the SAME names as the real jobs to satisfy
# required status checks. This follows the dual-job same-name pattern from
# pester-tests.yml (see Issue #335 for details).

  # Skip job for individual agent reviews - uses matrix to match review job names
  skip-agent-reviews:
    name: ${{ matrix.agent }} Review
    needs: check-changes
    if: needs.check-changes.outputs.should-run != 'true'
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    permissions:
      contents: read

    strategy:
      matrix:
        include:
          - agent: security
          - agent: qa
          - agent: analyst
          - agent: architect
          - agent: devops
          - agent: roadmap

    steps:
      - name: Skip ${{ matrix.agent }} review (no relevant changes)
        run: |
          echo "‚úÖ ${{ matrix.agent }} review skipped - no relevant file changes detected"
          echo ""
          echo "This PR only contains changes to files that don't require AI review."
          echo "Status: PASS (skipped)"

  # Skip job for aggregate results - matches aggregate job name
  skip-aggregate:
    name: Aggregate Results
    needs: check-changes
    if: needs.check-changes.outputs.should-run != 'true'
    # ADR-025: ARM runner for cost optimization (37.5% savings vs x64)
    runs-on: ubuntu-24.04-arm
    permissions:
      contents: read

    steps:
      - name: Skip AI review (no relevant file changes)
        run: |
          echo "‚úÖ AI Quality Gate skipped - no relevant file changes detected"
          echo ""
          echo "This PR only contains changes to files that don't require AI review:"
          echo "  - Documentation files (*.md, *.txt, *.rst, docs/**)"
          echo "  - Non-code files outside monitored paths"
          echo ""
          echo "Monitored paths that would trigger AI review:"
          echo "  - src/**"
          echo "  - scripts/**"
          echo "  - build/**"
          echo "  - .github/**"
          echo "  - .agents/**"
          echo "  - .claude/skills/**"
          echo ""
          echo "Status: PASS (skipped - no relevant changes)"
